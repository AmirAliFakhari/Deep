| Title / Hook                                       | Essential points & visuals                                                                                                   | Tips                                                                 |
| -------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------- |
| Course trailer                                     | Stunning real‑world DL successes (AlphaFold, StableDiffusion, ChatGPT).                                                      | 10 second videos / GIFs work better than screenshots.                |
| Two views of intelligence                          | 1. **Symbolic**  2. **Associationist**  3. **Connectionist**                                                                 |                                                                      |
| The perceptron legacy                              | Linear separator; limitation (XOR).                                                                                          | Animate the decision boundary moving.                                |
| AI winters & revivals                              | Very short timeline; takeaway: compute + data + optimisation unlocked depth.                                                 |                                                                      |
| Transition slide: “From philosophy to probability” | One arrow on screen from brains → data.                                                                                      |                                                                      |
| Data‑generating process                            | Random variable; p(x, y); IID assumption.                                                                                    | Use a simple scatter plot with noise.                                |
| Modelling & *inductive bias*                       | Why we restrict hypothesis class; link to **Occam’s razor**.                                                                 |                                                                      |
| Statistical learning basics                        | • Empirical vs true risk <br>• Bias‑variance picture <br>• Overfitting demo in 1‑D polynomial regression.                    | Jupyter/Colab demo embedded as GIF or link.                          |
| Maximum Likelihood ↔ Cross‑Entropy                 | Derive negative log‑likelihood for classification; preview of softmax.                                                       |                                                                      |
| Bayesian aside (30 s)                              | Posterior ∝ Likelihood × Prior; contrast with point estimates.                                                               |                                                                      |
| Transition: “We have an objective – now what?”     | Fade in gradient icon.                                                                                                       |                                                                      |
| Optimisation crash‑course                          | • Gradient / directional derivative <br>• Batch vs stochastic GD <br>• Line search intuition <br>• Convex vs non‑convex.     | Plot loss surface of Rosenbrock; then “bumpy‑but‑learnable” NN loss. |
| Auto‑diff concept                                  | Computational graph, chain rule, “back‑prop”.                                                                                |                                                                      |
| Regularisation as constraints                      | L2, dropout = noise injection; connects to Bayesian priors.                                                                  |                                                                      |
| Transition: “Enter Neural Networks”                | Show zoom‑in from logistic unit → hidden layer → deep stack.                                                                 |                                                                      |
| NN building blocks                                 | • Linear transform (Wx + b) <br>• Non‑linearities (ReLU family) <br>• Stacking ⇒ Universal Approximation (1 slide, no proof) |                                                                      |
| Capacity & depth                                   | Width vs depth diagrams; cite Telgarsky 2016 illustration.                                                                   |                                                                      |
| Training loop in practice                          | Data loader → forward → loss → backward → update. Pseudo‑code ≈ 10 lines.                                                    |                                                                      |
| Small hands‑on teaser                              | Train a 2‑layer net on MNIST subset live (or pre‑record 1‑min speed‑run).                                                    |                                                                      |
| Where are we going?                                | Map of coming weeks: CNNs, optimisation tricks, generalisation theory, Transformers.                                         |                                                                      |
| Meta‑skills                                        | Reproducibility, reading papers, ethical considerations.                                                                     |                                                                      |
| Resources & prerequisites recap                    | Pointer to “Math for DL” cheat sheet you will provide.                                                                       |                                                                      |
| Exit ticket                                        | One‑minute paper: “What still feels fuzzy?” Use QR code to Poll‑Everywhere.                                                  |                                                                      |
